{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc751a22-dca0-45b0-a055-f4b2efba6d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Error: 0.4977550305860017\n",
      "Epoch 1000 Error: 0.48962844155619734\n",
      "Epoch 2000 Error: 0.430505591830237\n",
      "Epoch 3000 Error: 0.335726373976126\n",
      "Epoch 4000 Error: 0.17357496319517723\n",
      "Epoch 5000 Error: 0.11181272498560173\n",
      "Epoch 6000 Error: 0.08576413241547484\n",
      "Epoch 7000 Error: 0.07130866479694536\n",
      "Epoch 8000 Error: 0.061975191385776986\n",
      "Epoch 9000 Error: 0.05537218409879135\n",
      "Final Predicted Output:\n",
      "[[0.05322146]\n",
      " [0.95171535]\n",
      " [0.95160449]\n",
      " [0.05175396]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 定义激活函数（Sigmoid）和它的导数\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# 创建训练数据（输入和对应的输出）\n",
    "inputs = np.array([[0, 0],\n",
    "                   [0, 1],\n",
    "                   [1, 0],\n",
    "                   [1, 1]])\n",
    "# 输出目标\n",
    "outputs = np.array([[0], [1], [1], [0]])  # XOR 问题\n",
    "\n",
    "# 设置随机种子，方便结果复现\n",
    "np.random.seed(42)\n",
    "\n",
    "# 初始化权重和偏置\n",
    "input_layer_neurons = inputs.shape[1]  # 输入层神经元数量\n",
    "hidden_layer_neurons = 2  # 隐藏层神经元数量\n",
    "output_layer_neurons = 1  # 输出层神经元数量\n",
    "\n",
    "# 随机初始化权重和偏置\n",
    "hidden_weights = np.random.uniform(size=(input_layer_neurons, hidden_layer_neurons))\n",
    "hidden_bias = np.random.uniform(size=(1, hidden_layer_neurons))\n",
    "output_weights = np.random.uniform(size=(hidden_layer_neurons, output_layer_neurons))\n",
    "output_bias = np.random.uniform(size=(1, output_layer_neurons))\n",
    "\n",
    "# 学习率\n",
    "learning_rate = 0.1\n",
    "\n",
    "# 训练神经网络\n",
    "for epoch in range(10000):\n",
    "    # 前向传播\n",
    "    hidden_layer_input = np.dot(inputs, hidden_weights) + hidden_bias\n",
    "    hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "\n",
    "    output_layer_input = np.dot(hidden_layer_output, output_weights) + output_bias\n",
    "    predicted_output = sigmoid(output_layer_input)\n",
    "\n",
    "    # 计算误差\n",
    "    error = outputs - predicted_output\n",
    "\n",
    "    # 反向传播\n",
    "    d_predicted_output = error * sigmoid_derivative(predicted_output)\n",
    "    error_hidden_layer = d_predicted_output.dot(output_weights.T)\n",
    "    d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
    "\n",
    "    # 更新权重和偏置\n",
    "    output_weights += hidden_layer_output.T.dot(d_predicted_output) * learning_rate\n",
    "    output_bias += np.sum(d_predicted_output, axis=0, keepdims=True) * learning_rate\n",
    "    hidden_weights += inputs.T.dot(d_hidden_layer) * learning_rate\n",
    "    hidden_bias += np.sum(d_hidden_layer, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "    # 可选：打印误差\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch {epoch} Error: {np.mean(np.abs(error))}\")\n",
    "\n",
    "# 输出最终预测结果\n",
    "print(\"Final Predicted Output:\")\n",
    "print(predicted_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f40e8a76-7cec-44b5-a03f-6560c56c8b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Error: 0.4997696391493412\n",
      "Epoch 1000 Error: 0.4998937388021379\n",
      "Epoch 2000 Error: 0.4998416978559803\n",
      "Epoch 3000 Error: 0.4997636684703226\n",
      "Epoch 4000 Error: 0.4996426637699034\n",
      "Epoch 5000 Error: 0.49944600255407234\n",
      "Epoch 6000 Error: 0.49910315041712877\n",
      "Epoch 7000 Error: 0.4984348114780567\n",
      "Epoch 8000 Error: 0.4968586094361822\n",
      "Epoch 9000 Error: 0.49162972629566004\n",
      "Epoch 10000 Error: 0.4652951018636178\n",
      "Epoch 11000 Error: 0.40479378327252047\n",
      "Epoch 12000 Error: 0.3752996718637253\n",
      "Epoch 13000 Error: 0.3632102513899902\n",
      "Epoch 14000 Error: 0.35662678309242424\n",
      "Epoch 15000 Error: 0.35179251460520644\n",
      "Epoch 16000 Error: 0.34316538116976497\n",
      "Epoch 17000 Error: 0.1369511768275634\n",
      "Epoch 18000 Error: 0.07485284401801086\n",
      "Epoch 19000 Error: 0.055456139070491836\n",
      "Epoch 20000 Error: 0.04559174008910105\n",
      "Epoch 21000 Error: 0.03945032290248348\n",
      "Epoch 22000 Error: 0.03518418120892469\n",
      "Epoch 23000 Error: 0.032010250266999246\n",
      "Epoch 24000 Error: 0.029535316812391202\n",
      "Epoch 25000 Error: 0.027538349327775703\n",
      "Epoch 26000 Error: 0.025884655324559535\n",
      "Epoch 27000 Error: 0.024487015240214835\n",
      "Epoch 28000 Error: 0.023286208338192855\n",
      "Epoch 29000 Error: 0.022240465100802142\n",
      "Epoch 30000 Error: 0.021319390187753414\n",
      "Epoch 31000 Error: 0.02050028041225441\n",
      "Epoch 32000 Error: 0.019765798584526394\n",
      "Epoch 33000 Error: 0.019102451122214543\n",
      "Epoch 34000 Error: 0.01849956112104502\n",
      "Epoch 35000 Error: 0.017948557265067576\n",
      "Epoch 36000 Error: 0.01744247003363674\n",
      "Epoch 37000 Error: 0.016975567491130245\n",
      "Epoch 38000 Error: 0.01654308721609604\n",
      "Epoch 39000 Error: 0.016141035796791783\n",
      "Epoch 40000 Error: 0.01576603667882233\n",
      "Epoch 41000 Error: 0.01541521318381615\n",
      "Epoch 42000 Error: 0.015086097492526988\n",
      "Epoch 43000 Error: 0.014776559055725723\n",
      "Epoch 44000 Error: 0.01448474772211917\n",
      "Epoch 45000 Error: 0.01420904814165698\n",
      "Epoch 46000 Error: 0.013948042897978264\n",
      "Epoch 47000 Error: 0.013700482464223323\n",
      "Epoch 48000 Error: 0.01346526054039778\n",
      "Epoch 49000 Error: 0.013241393670572824\n",
      "Epoch 50000 Error: 0.013028004290222779\n",
      "Epoch 51000 Error: 0.01282430654267771\n",
      "Epoch 52000 Error: 0.012629594346266503\n",
      "Epoch 53000 Error: 0.01244323130246443\n",
      "Epoch 54000 Error: 0.01226464211897444\n",
      "Epoch 55000 Error: 0.012093305286472119\n",
      "Epoch 56000 Error: 0.011928746798339634\n",
      "Epoch 57000 Error: 0.011770534742494818\n",
      "Epoch 58000 Error: 0.011618274625902265\n",
      "Epoch 59000 Error: 0.011471605317426034\n",
      "Epoch 60000 Error: 0.011330195514770953\n",
      "Epoch 61000 Error: 0.011193740657439263\n",
      "Epoch 62000 Error: 0.011061960220734543\n",
      "Epoch 63000 Error: 0.010934595336518515\n",
      "Epoch 64000 Error: 0.010811406695147631\n",
      "Epoch 65000 Error: 0.010692172690192374\n",
      "Epoch 66000 Error: 0.010576687773461692\n",
      "Epoch 67000 Error: 0.010464760992762669\n",
      "Epoch 68000 Error: 0.010356214688906677\n",
      "Epoch 69000 Error: 0.010250883331891485\n",
      "Epoch 70000 Error: 0.010148612479042763\n",
      "Epoch 71000 Error: 0.010049257840313302\n",
      "Epoch 72000 Error: 0.009952684437968998\n",
      "Epoch 73000 Error: 0.009858765849611935\n",
      "Epoch 74000 Error: 0.009767383524959377\n",
      "Epoch 75000 Error: 0.00967842616804165\n",
      "Epoch 76000 Error: 0.009591789177552585\n",
      "Epoch 77000 Error: 0.009507374138998041\n",
      "Epoch 78000 Error: 0.009425088363079445\n",
      "Epoch 79000 Error: 0.009344844465421824\n",
      "Epoch 80000 Error: 0.009266559983347059\n",
      "Epoch 81000 Error: 0.009190157025896399\n",
      "Epoch 82000 Error: 0.009115561953751952\n",
      "Epoch 83000 Error: 0.009042705086087115\n",
      "Epoch 84000 Error: 0.00897152043171081\n",
      "Epoch 85000 Error: 0.008901945442165307\n",
      "Epoch 86000 Error: 0.008833920784691862\n",
      "Epoch 87000 Error: 0.00876739013320445\n",
      "Epoch 88000 Error: 0.008702299975608669\n",
      "Epoch 89000 Error: 0.008638599435978668\n",
      "Epoch 90000 Error: 0.008576240110258291\n",
      "Epoch 91000 Error: 0.008515175914288043\n",
      "Epoch 92000 Error: 0.008455362943081881\n",
      "Epoch 93000 Error: 0.008396759340382861\n",
      "Epoch 94000 Error: 0.008339325177623574\n",
      "Epoch 95000 Error: 0.008283022341501026\n",
      "Epoch 96000 Error: 0.008227814429451209\n",
      "Epoch 97000 Error: 0.008173666652376479\n",
      "Epoch 98000 Error: 0.008120545744039238\n",
      "Epoch 99000 Error: 0.008068419876588772\n",
      "Final Predicted Output:\n",
      "[[0.00889126]\n",
      " [0.99282024]\n",
      " [0.99286761]\n",
      " [0.00886582]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 定义激活函数（Sigmoid）和它的导数\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# 创建训练数据（输入和对应的输出）\n",
    "inputs = np.array([[0, 0],\n",
    "                   [0, 1],\n",
    "                   [1, 0],\n",
    "                   [1, 1]])\n",
    "# 输出目标\n",
    "outputs = np.array([[0], [1], [1], [0]])  # XOR 问题\n",
    "\n",
    "# 设置随机种子，方便结果复现\n",
    "np.random.seed(42)\n",
    "\n",
    "# 初始化权重和偏置\n",
    "input_layer_neurons = inputs.shape[1]  # 输入层神经元数量\n",
    "hidden_layer1_neurons = 3  # 第一层隐藏层神经元数量\n",
    "hidden_layer2_neurons = 2  # 第二层隐藏层神经元数量\n",
    "output_layer_neurons = 1  # 输出层神经元数量\n",
    "\n",
    "# 随机初始化权重和偏置\n",
    "hidden_weights1 = np.random.uniform(size=(input_layer_neurons, hidden_layer1_neurons))\n",
    "hidden_bias1 = np.random.uniform(size=(1, hidden_layer1_neurons))\n",
    "\n",
    "hidden_weights2 = np.random.uniform(size=(hidden_layer1_neurons, hidden_layer2_neurons))\n",
    "hidden_bias2 = np.random.uniform(size=(1, hidden_layer2_neurons))\n",
    "\n",
    "output_weights = np.random.uniform(size=(hidden_layer2_neurons, output_layer_neurons))\n",
    "output_bias = np.random.uniform(size=(1, output_layer_neurons))\n",
    "\n",
    "# 学习率\n",
    "learning_rate = 0.1\n",
    "\n",
    "# 训练神经网络\n",
    "for epoch in range(100000):\n",
    "    # 前向传播\n",
    "    hidden_layer1_input = np.dot(inputs, hidden_weights1) + hidden_bias1\n",
    "    hidden_layer1_output = sigmoid(hidden_layer1_input)\n",
    "\n",
    "    hidden_layer2_input = np.dot(hidden_layer1_output, hidden_weights2) + hidden_bias2\n",
    "    hidden_layer2_output = sigmoid(hidden_layer2_input)\n",
    "\n",
    "    output_layer_input = np.dot(hidden_layer2_output, output_weights) + output_bias\n",
    "    predicted_output = sigmoid(output_layer_input)\n",
    "\n",
    "    # 计算误差\n",
    "    error = outputs - predicted_output\n",
    "\n",
    "    # 反向传播\n",
    "    d_predicted_output = error * sigmoid_derivative(predicted_output)\n",
    "    error_hidden_layer2 = d_predicted_output.dot(output_weights.T)\n",
    "    d_hidden_layer2 = error_hidden_layer2 * sigmoid_derivative(hidden_layer2_output)\n",
    "\n",
    "    error_hidden_layer1 = d_hidden_layer2.dot(hidden_weights2.T)\n",
    "    d_hidden_layer1 = error_hidden_layer1 * sigmoid_derivative(hidden_layer1_output)\n",
    "\n",
    "    # 更新权重和偏置\n",
    "    output_weights += hidden_layer2_output.T.dot(d_predicted_output) * learning_rate\n",
    "    output_bias += np.sum(d_predicted_output, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "    hidden_weights2 += hidden_layer1_output.T.dot(d_hidden_layer2) * learning_rate\n",
    "    hidden_bias2 += np.sum(d_hidden_layer2, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "    hidden_weights1 += inputs.T.dot(d_hidden_layer1) * learning_rate\n",
    "    hidden_bias1 += np.sum(d_hidden_layer1, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "    # 可选：打印误差\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch {epoch} Error: {np.mean(np.abs(error))}\")\n",
    "\n",
    "# 输出最终预测结果\n",
    "print(\"Final Predicted Output:\")\n",
    "print(predicted_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17509493-2c16-4dd6-b66f-1beb203f2ebd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/songguo77/miniconda3/envs/py310/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.0000e+00 - loss: 0.7250 - val_accuracy: 1.0000 - val_loss: 0.2641\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.0000e+00 - loss: 0.7221 - val_accuracy: 1.0000 - val_loss: 0.2649\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.0000e+00 - loss: 0.7193 - val_accuracy: 1.0000 - val_loss: 0.2657\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.0000e+00 - loss: 0.7168 - val_accuracy: 1.0000 - val_loss: 0.2665\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6667 - loss: 0.7143 - val_accuracy: 1.0000 - val_loss: 0.2672\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6667 - loss: 0.7119 - val_accuracy: 1.0000 - val_loss: 0.2679\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6667 - loss: 0.7094 - val_accuracy: 1.0000 - val_loss: 0.2684\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6667 - loss: 0.7070 - val_accuracy: 1.0000 - val_loss: 0.2689\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6667 - loss: 0.7048 - val_accuracy: 1.0000 - val_loss: 0.2694\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6667 - loss: 0.7026 - val_accuracy: 1.0000 - val_loss: 0.2698\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.6667 - loss: 0.7005 - val_accuracy: 1.0000 - val_loss: 0.2702\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6667 - loss: 0.6984 - val_accuracy: 1.0000 - val_loss: 0.2705\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6667 - loss: 0.6963 - val_accuracy: 1.0000 - val_loss: 0.2708\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6667 - loss: 0.6942 - val_accuracy: 1.0000 - val_loss: 0.2711\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6667 - loss: 0.6921 - val_accuracy: 1.0000 - val_loss: 0.2714\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6667 - loss: 0.6900 - val_accuracy: 1.0000 - val_loss: 0.2717\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6667 - loss: 0.6879 - val_accuracy: 1.0000 - val_loss: 0.2719\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6667 - loss: 0.6858 - val_accuracy: 1.0000 - val_loss: 0.2721\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6667 - loss: 0.6837 - val_accuracy: 1.0000 - val_loss: 0.2724\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6667 - loss: 0.6817 - val_accuracy: 1.0000 - val_loss: 0.2726\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6667 - loss: 0.6796 - val_accuracy: 1.0000 - val_loss: 0.2728\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.6667 - loss: 0.6776 - val_accuracy: 1.0000 - val_loss: 0.2731\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6667 - loss: 0.6755 - val_accuracy: 1.0000 - val_loss: 0.2733\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6667 - loss: 0.6735 - val_accuracy: 1.0000 - val_loss: 0.2736\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6667 - loss: 0.6715 - val_accuracy: 1.0000 - val_loss: 0.2738\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6667 - loss: 0.6694 - val_accuracy: 1.0000 - val_loss: 0.2741\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6667 - loss: 0.6674 - val_accuracy: 1.0000 - val_loss: 0.2743\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6667 - loss: 0.6654 - val_accuracy: 1.0000 - val_loss: 0.2746\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6667 - loss: 0.6634 - val_accuracy: 1.0000 - val_loss: 0.2749\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6667 - loss: 0.6614 - val_accuracy: 1.0000 - val_loss: 0.2751\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6667 - loss: 0.6594 - val_accuracy: 1.0000 - val_loss: 0.2754\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6667 - loss: 0.6575 - val_accuracy: 1.0000 - val_loss: 0.2757\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6667 - loss: 0.6555 - val_accuracy: 1.0000 - val_loss: 0.2759\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6667 - loss: 0.6535 - val_accuracy: 1.0000 - val_loss: 0.2762\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6667 - loss: 0.6516 - val_accuracy: 1.0000 - val_loss: 0.2764\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6667 - loss: 0.6496 - val_accuracy: 1.0000 - val_loss: 0.2767\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6667 - loss: 0.6477 - val_accuracy: 1.0000 - val_loss: 0.2769\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6667 - loss: 0.6457 - val_accuracy: 1.0000 - val_loss: 0.2771\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6667 - loss: 0.6438 - val_accuracy: 1.0000 - val_loss: 0.2773\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6667 - loss: 0.6418 - val_accuracy: 1.0000 - val_loss: 0.2775\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6667 - loss: 0.6399 - val_accuracy: 1.0000 - val_loss: 0.2777\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.6380 - val_accuracy: 1.0000 - val_loss: 0.2779\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.6361 - val_accuracy: 1.0000 - val_loss: 0.2781\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.6342 - val_accuracy: 1.0000 - val_loss: 0.2783\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.6323 - val_accuracy: 1.0000 - val_loss: 0.2784\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.6304 - val_accuracy: 1.0000 - val_loss: 0.2786\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.6285 - val_accuracy: 1.0000 - val_loss: 0.2787\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.6266 - val_accuracy: 1.0000 - val_loss: 0.2789\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.6247 - val_accuracy: 1.0000 - val_loss: 0.2790\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.6228 - val_accuracy: 1.0000 - val_loss: 0.2792\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.6209 - val_accuracy: 1.0000 - val_loss: 0.2793\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.6190 - val_accuracy: 1.0000 - val_loss: 0.2794\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.6172 - val_accuracy: 1.0000 - val_loss: 0.2796\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.6153 - val_accuracy: 1.0000 - val_loss: 0.2797\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.6134 - val_accuracy: 1.0000 - val_loss: 0.2799\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.6116 - val_accuracy: 1.0000 - val_loss: 0.2800\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.6097 - val_accuracy: 1.0000 - val_loss: 0.2801\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.6079 - val_accuracy: 1.0000 - val_loss: 0.2803\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.6060 - val_accuracy: 1.0000 - val_loss: 0.2804\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.6042 - val_accuracy: 1.0000 - val_loss: 0.2806\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.6025 - val_accuracy: 1.0000 - val_loss: 0.2807\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.6010 - val_accuracy: 1.0000 - val_loss: 0.2808\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.5995 - val_accuracy: 1.0000 - val_loss: 0.2810\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.5980 - val_accuracy: 1.0000 - val_loss: 0.2812\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.5965 - val_accuracy: 1.0000 - val_loss: 0.2813\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 0.5950 - val_accuracy: 1.0000 - val_loss: 0.2815\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.5935 - val_accuracy: 1.0000 - val_loss: 0.2816\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.5920 - val_accuracy: 1.0000 - val_loss: 0.2818\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.5905 - val_accuracy: 1.0000 - val_loss: 0.2819\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.5890 - val_accuracy: 1.0000 - val_loss: 0.2821\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.5876 - val_accuracy: 1.0000 - val_loss: 0.2822\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.5861 - val_accuracy: 1.0000 - val_loss: 0.2824\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.5846 - val_accuracy: 1.0000 - val_loss: 0.2825\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.5831 - val_accuracy: 1.0000 - val_loss: 0.2827\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.5816 - val_accuracy: 1.0000 - val_loss: 0.2828\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.5801 - val_accuracy: 1.0000 - val_loss: 0.2829\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.5786 - val_accuracy: 1.0000 - val_loss: 0.2831\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.5771 - val_accuracy: 1.0000 - val_loss: 0.2832\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.5756 - val_accuracy: 1.0000 - val_loss: 0.2833\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.5741 - val_accuracy: 1.0000 - val_loss: 0.2835\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.5726 - val_accuracy: 1.0000 - val_loss: 0.2836\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.5711 - val_accuracy: 1.0000 - val_loss: 0.2837\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.5696 - val_accuracy: 1.0000 - val_loss: 0.2838\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.5681 - val_accuracy: 1.0000 - val_loss: 0.2839\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.5666 - val_accuracy: 1.0000 - val_loss: 0.2840\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.5651 - val_accuracy: 1.0000 - val_loss: 0.2841\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.5636 - val_accuracy: 1.0000 - val_loss: 0.2842\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.5621 - val_accuracy: 1.0000 - val_loss: 0.2843\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.5606 - val_accuracy: 1.0000 - val_loss: 0.2844\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.5591 - val_accuracy: 1.0000 - val_loss: 0.2845\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.5576 - val_accuracy: 1.0000 - val_loss: 0.2846\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.5561 - val_accuracy: 1.0000 - val_loss: 0.2847\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.5546 - val_accuracy: 1.0000 - val_loss: 0.2848\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.5531 - val_accuracy: 1.0000 - val_loss: 0.2849\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.5516 - val_accuracy: 1.0000 - val_loss: 0.2849\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.5501 - val_accuracy: 1.0000 - val_loss: 0.2850\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.5486 - val_accuracy: 1.0000 - val_loss: 0.2851\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.5471 - val_accuracy: 1.0000 - val_loss: 0.2851\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.5455 - val_accuracy: 1.0000 - val_loss: 0.2852\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.5440 - val_accuracy: 1.0000 - val_loss: 0.2852\n",
      "Training finished\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.2852\n",
      "Test Loss: 0.2852, Test Accuracy: 1.0000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Predictions on test data:\n",
      "[[0.7518588]]\n",
      "test:\n",
      "[[-1.  1.]]\n",
      "[[1]]\n",
      "Weight 0:\n",
      "[[ 0.6690341  -0.6875728   0.46426955 -0.27887362  0.2810142  -0.3728916\n",
      "  -0.20174886 -0.54573184]\n",
      " [-0.5313867   0.6747879   0.2174806  -0.42462355  0.8455625  -0.362144\n",
      "  -0.04211799  0.1408405 ]]\n",
      "Weight 1:\n",
      "[ 0.10333838 -0.01727811 -0.08042245 -0.08530567  0.11184133  0.00098146\n",
      " -0.06572448  0.06865425]\n",
      "Weight 2:\n",
      "[[ 0.40721834 -0.54268265  0.22533     0.19566442]\n",
      " [ 0.12914956 -0.19665164 -0.3995635   0.5314794 ]\n",
      " [-0.03648835 -0.29543743  0.44373715  0.22907366]\n",
      " [-0.17006166  0.34744233 -0.11171935 -0.4587607 ]\n",
      " [-0.28161865 -0.45347765  0.61060613 -0.0273956 ]\n",
      " [-0.49634036 -0.10166877 -0.06012787 -0.4722161 ]\n",
      " [ 0.5337433   0.47475877 -0.20253378 -0.30700117]\n",
      " [ 0.3659225  -0.46380025 -0.05744129  0.5753053 ]]\n",
      "Weight 3:\n",
      "[ 0.09835502 -0.06696086 -0.01056936  0.01043428]\n",
      "Weight 4:\n",
      "[[ 0.80507785]\n",
      " [ 0.3654908 ]\n",
      " [-0.456055  ]\n",
      " [ 0.79714084]]\n",
      "Weight 5:\n",
      "[-0.09764595]\n",
      "Layer: dense_6\n",
      "(2, 8)\n",
      "(8,)\n",
      "Layer: dense_7\n",
      "(8, 4)\n",
      "(4,)\n",
      "Layer: dense_8\n",
      "(4, 1)\n",
      "(1,)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 71\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m weights:\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;28mprint\u001b[39m(w\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 71\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(\u001b[43mx\u001b[49m, y, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOriginal data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     72\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(x_test, y_pred, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrediction\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     73\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.api.models import Sequential\n",
    "from keras.api.layers import Dense\n",
    "from keras.api.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 创建训练数据（XOR 问题）\n",
    "X = np.array([[0, 0],\n",
    "              [0, 1],\n",
    "              [1, 0],\n",
    "              [1, 1]])\n",
    "\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# 数据标准化：将输入特征进行归一化/标准化处理\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 划分训练集和测试集（这里使用全部数据进行训练，实际中会有更多数据）\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建神经网络模型\n",
    "model = Sequential()\n",
    "\n",
    "# 第一层隐藏层，包含 8 个神经元，激活函数为 ReLU\n",
    "model.add(Dense(8, input_dim=2, activation='relu'))\n",
    "\n",
    "# 第二层隐藏层，包含 4 个神经元，激活函数为 ReLU\n",
    "model.add(Dense(4, activation='relu'))\n",
    "\n",
    "# 输出层，包含一个神经元，激活函数为 Sigmoid（二分类问题）\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 编译模型，选择 Adam 优化器，损失函数使用二分类交叉熵，评估指标选择准确率\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型，使用 1000 次迭代，并设置验证集来防止过拟合\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=4, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# 打印最终的训练结果\n",
    "print(\"Training finished\")\n",
    "\n",
    "# 在测试集上评估模型表现\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 进行预测\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Predictions on test data:\")\n",
    "print(predictions)\n",
    "print(\"test:\")\n",
    "print(X_test)\n",
    "print(y_test)\n",
    "\n",
    "weights = model.get_weights()\n",
    "\n",
    "# 输出权重\n",
    "for i, weight in enumerate(weights):\n",
    "    print(f\"Weight {i}:\")\n",
    "    print(weight)\n",
    "\n",
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    for w in weights:\n",
    "        print(w.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0c70ca2-4488-4482-877e-c3e1b8990262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.17.0\n",
      "GPU available: []\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b40034b-dd78-4760-a371-567c0b981c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-23 13:44:19.452092: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/songguo77/miniconda3/envs/py310/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.12080\n",
      "Epoch 2/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7823  \n",
      "Epoch 3/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4902 \n",
      "Epoch 4/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1673  \n",
      "Epoch 5/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.93393\n",
      "Epoch 6/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7794  \n",
      "Epoch 7/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6127  \n",
      "Epoch 8/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5292  \n",
      "Epoch 9/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4328  \n",
      "Epoch 10/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3323  \n",
      "Epoch 11/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2728 \n",
      "Epoch 12/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2198\n",
      "Epoch 13/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1821  \n",
      "Epoch 14/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1458 \n",
      "Epoch 15/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1179  \n",
      "Epoch 16/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1078\n",
      "Epoch 17/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.08737\n",
      "Epoch 18/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0793\n",
      "Epoch 19/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0644  \n",
      "Epoch 20/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0505  \n",
      "Epoch 21/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0465  \n",
      "Epoch 22/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0402\n",
      "Epoch 23/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0351 \n",
      "Epoch 24/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0295\n",
      "Epoch 25/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0262\n",
      "Epoch 26/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0231 \n",
      "Epoch 27/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0216  \n",
      "Epoch 28/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.01947\n",
      "Epoch 29/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0190\n",
      "Epoch 30/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0174  \n",
      "Epoch 31/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0156  \n",
      "Epoch 32/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0160\n",
      "Epoch 33/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0156\n",
      "Epoch 34/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0157 \n",
      "Epoch 35/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0147 \n",
      "Epoch 36/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0137  \n",
      "Epoch 37/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.01302\n",
      "Epoch 38/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133\n",
      "Epoch 39/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 \n",
      "Epoch 40/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0128\n",
      "Epoch 41/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136  \n",
      "Epoch 42/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0132  \n",
      "Epoch 43/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121\n",
      "Epoch 44/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 \n",
      "Epoch 45/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117\n",
      "Epoch 46/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123\n",
      "Epoch 47/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117\n",
      "Epoch 48/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129  \n",
      "Epoch 49/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116  \n",
      "Epoch 50/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114  \n",
      "Epoch 51/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 1\n",
      "Epoch 52/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110  \n",
      "Epoch 53/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117  \n",
      "Epoch 54/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 \n",
      "Epoch 55/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115\n",
      "Epoch 56/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109\n",
      "Epoch 57/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.01325\n",
      "Epoch 58/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121\n",
      "Epoch 59/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123\n",
      "Epoch 60/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119  \n",
      "Epoch 61/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111  \n",
      "Epoch 62/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0110\n",
      "Epoch 63/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.01141\n",
      "Epoch 64/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.01110\n",
      "Epoch 65/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111  \n",
      "Epoch 66/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112\n",
      "Epoch 67/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110\n",
      "Epoch 68/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120\n",
      "Epoch 69/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110  \n",
      "Epoch 70/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110\n",
      "Epoch 71/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108  \n",
      "Epoch 72/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0110  \n",
      "Epoch 73/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115\n",
      "Epoch 74/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115\n",
      "Epoch 75/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 \n",
      "Epoch 76/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.01242\n",
      "Epoch 77/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.01080\n",
      "Epoch 78/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113\n",
      "Epoch 79/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0108  \n",
      "Epoch 80/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109  \n",
      "Epoch 81/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 \n",
      "Epoch 82/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119  \n",
      "Epoch 83/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105  \n",
      "Epoch 84/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109  \n",
      "Epoch 85/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102  \n",
      "Epoch 86/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0109\n",
      "Epoch 87/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102  \n",
      "Epoch 88/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107  \n",
      "Epoch 89/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111\n",
      "Epoch 90/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.01152\n",
      "Epoch 91/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115  \n",
      "Epoch 92/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109  \n",
      "Epoch 93/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 \n",
      "Epoch 94/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116\n",
      "Epoch 95/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 \n",
      "Epoch 96/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104\n",
      "Epoch 97/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113\n",
      "Epoch 98/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102  \n",
      "Epoch 99/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104\n",
      "Epoch 100/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0107  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "[[1.2951154]\n",
      " [2.0139806]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 生成随机数据\n",
    "x = np.random.rand(100, 1)\n",
    "y = 2 * x + 1 + 0.1*np.random.randn(100, 1)\n",
    "\n",
    "# 定义模型\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=1, input_shape=[1])\n",
    "])\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "\n",
    "# 训练模型\n",
    "model.fit(x, y, epochs=100)\n",
    "\n",
    "# 预测新数据\n",
    "x_test = np.array([[0.1], [0.5]])\n",
    "y_pred = model.predict(x_test)\n",
    "print(y_pred)\n",
    "\n",
    "# 可视化\n",
    "plt.scatter(x, y, label='Original data')\n",
    "plt.plot(x_test, y_pred, color='red', label='Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fafe0e02-3567-45a7-b0f7-c176e0bc2eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.17.0\n",
      "GPU available: []\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24713e46-9f45-4f95-8399-7a4f428fb687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "现在是下午5点，记得做总结！\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     schedule\u001b[38;5;241m.\u001b[39mrun_pending()\n\u001b[0;32m---> 14\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import schedule\n",
    "import os\n",
    "import time\n",
    "\n",
    "def remind():\n",
    "    os.system('osascript -e \\'display notification \"记得总结今天的工作！\" with title \"总结提醒\"\\'')\n",
    "    print(\"现在是下午5点，记得做总结！\")\n",
    "\n",
    "# 每天下午 5 点执行\n",
    "schedule.every().day.at(\"13:46\").do(remind)\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bcc841-4c21-4235-a6ac-d37039788122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
